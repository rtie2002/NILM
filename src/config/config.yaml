# Model configuration
model:
  name: 'unet'
  input_size: 100
  hidden_size: 64
  num_layers: 2
  dropout: 0.2

# Training configuration
training:
  batch_size: 32
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 1e-5

# Data configuration
data:
  path: '../data/raw'
  processed_path: '../data/processed'
  test_size: 0.2
  val_size: 0.1
  random_state: 42

# Logging configuration
logging:
  level: 'INFO'
  file: 'logs/nilm_training.log'
